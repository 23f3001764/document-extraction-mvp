# ğŸ“„ Document Extraction MVP (Utilities Domain)

> **Assignment 1 â€“ Document Extraction MVP**  
> Domain: **Electricity Utilities**  
> Variants Implemented: **Variant C (Rule-based + SQLite)** and **Variant B (SLM + Postgres)**

---

## ğŸ“Œ Overview

This project builds a **working MVP** that reads long, complex PDFs (both digital and scanned), extracts structured information using OCR and language models, stores the data in a database, and provides a **simple web UI** for search and filtering.

The system supports **three document types**:

1. **Indian Constitution PDFs**
2. **Engineering Mathematics Textbooks**
3. **Electricity Utility Bills**

The application supports **two variants**, switchable at runtime via the UI:

- **Variant C** â€“ Rule-based extraction + SQLite (fast, lightweight)
- **Variant B** â€“ Small Language Model (SLM) extraction + Postgres (more intelligent)

---

## ğŸ— Architecture

PDF â†’ OCR â†’ Chunking â†’ Extraction â†’ Database â†’ Streamlit UI

---

## ğŸ§  Variants Explained

### ğŸ”¹ Variant C (Default â€“ Fast MVP)
- OCR: Tesseract
- Extraction: Regex / rules
- Database: SQLite
- UI: Streamlit

### ğŸ”¹ Variant B (Advanced)
- OCR: Tesseract
- Extraction: Small Language Model (Qwen 0.5B)
- Database: PostgreSQL
- UI: Streamlit (runtime switch)

---

## ğŸ“‚ Supported Schemas

### Constitution
- article_number
- article_title
- part
- part_title
- article_text

### Math Book
- unit
- section
- example_number
- example_title

### Electricity Bill
- meter_id
- bill_date
- kwh
- amount_payable
- location

---

## ğŸ–¥ Web Interface

Tabs:
1. Constitution Search  
2. Math Book Browser  
3. Electricity Bills  
4. Upload PDF (with Variant switch)

---

## âš™ï¸ Local Setup

```bash
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
streamlit run app.py
```

---

## ğŸ³ Docker Deployment

```bash
docker compose up -d --build
```

Open: http://localhost:8501

---

## ğŸš§ Limitations
- CPU-only SLM is slow
- OCR quality depends on scan
- Constitution SLM limited to few chunks (MVP)

---
## Cloud Deployment

The application is designed to be deployed on a cloud VM (e.g., AWS EC2) using Docker Compose.

Deployment steps:
1. Provision an Ubuntu VM
2. Install Docker and Docker Compose
3. Clone the repository
4. Run `docker compose up -d --build`

The deployment runs three containers:
- PostgreSQL database
- One-time data loader (for initial PDF processing)
- Streamlit web application

This ensures the application is immediately usable after startup.

---

## ğŸš€ Future Improvements
- Vector search
- Fine-tuned SLM
- Async pipelines
- Better table extraction

---

## ğŸ‘¤ Author
**Sahil Raj**  
BS in Data Science & Applications